base_model_path: /Users/macbook2024/Library/CloudStorage/Dropbox/AAA Backup/A Working/Arjun
  LLM Writing/local_qwen/artifacts/base_model/Qwen2.5-7B-Instruct
batch_size: 2
cache_dir: ./OnPolicyDistill/teacher_cache
cache_size_mb: 4096
ce_weight: 0.19999999999999996
checkpoint_every: 100
eval_every: 100
experiment_name: null
generation_temperature: 1.0
gradient_accumulation_steps: 2
keep_last_n_checkpoints: 5
keep_teacher_loaded: true
kl_weight: 0.8
learning_rate: 1.0e-05
logprob_method: manual_loop
max_generation_tokens: 50
max_grad_norm: 1.0
max_prompts: 20
mixed_precision: true
num_steps: 10
num_workers: 0
output_adapter_path: ./OnPolicyDistill/checkpoints/test_run
run_id: distill_20251029_162724
save_best_only: false
seed: 42
session_id: null
student_adapter_path: /Users/macbook2024/Library/CloudStorage/Dropbox/AAA Backup/A
  Working/Arjun LLM Writing/local_qwen/artifacts/lora_adapters/7b
teacher_model_path: /Users/macbook2024/Library/CloudStorage/Dropbox/AAA Backup/A Working/Arjun
  LLM Writing/local_qwen/artifacts/base_model/Qwen3-32B-MLX-4bit
temperature: 2.0
train_val_split: 0.8
use_cache: true
use_teacher_targets: true
validation_prompts_path: ./OnPolicyDistill/test_prompts.jsonl
warmup_steps: 100
